<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.55.4" />


<title>Fitting and Interpreting a Proportional Odds Model - StatLab Articles</title>
<meta property="og:title" content="Fitting and Interpreting a Proportional Odds Model - StatLab Articles">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="378"
         height="71"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/"> About</a></li>
    
    <li><a href="/tags/"> Tags</a></li>
    
    <li><a href="https://data.library.virginia.edu/">RDS</a></li>
    
    <li><a href="https://www.library.virginia.edu/">UVA Library</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">11 min read</span>
    

    <h1 class="article-title">Fitting and Interpreting a Proportional Odds Model</h1>

    
    <span class="article-date">2015-10-05</span>
    

    <div class="article-content">
      


<p>Take a look at the following table. It is a cross tabulation of data taken from the 1991 General Social Survey that relates political party affiliation to political ideology. (Agresti, <em>An Introduction to Categorical Data Analysis</em>, 1996)</p>
<style type="text/css">
td
{
    padding:0 15px 0 15px;
    text-align: center;
}
caption
{
    font-size: 70%
}

</style>
<table class="demo">
<caption>
Political Ideology by Party Affiliation, from the 1991 General Social Survey
</caption>
<thead>
<tr>
<th>
<br>
</th>
<th>
Very <br>Liberal<br>
</th>
<th>
Slightly<br>Liberal<br>
</th>
<th>
Moderate
</th>
<th>
Slightly<br>Conservative<br>
</th>
<th>
Very <br>Conservative<br>
</th>
</tr>
</thead>
<tbody>
<tr>
<td>
<strong>Republican</strong><br>
</td>
<td>
30
</td>
<td>
46
</td>
<td>
148
</td>
<td>
84
</td>
<td>
99
</td>
</tr>
<tr>
<td>
<strong>Democratic</strong>
</td>
<td>
80 <br>
</td>
<td>
81
</td>
<td>
171
</td>
<td>
41
</td>
<td>
55
</td>
</tr>
</tbody>
</table>
<p>Not surprisingly, as we move across the table from left to right, response numbers for Democrats go down while those for Republicans go up. What if we wanted to model the probability of answering a particular political ideology given party affiliation? Since the political ideology categories have an ordering, we would want to use ordinal logistic regression.</p>
<p>There are several types of ordinal logistic regression models. Probably the most frequently used in practice is the proportional odds model. (Hosmer and Lemeshow, <em>Applied Logistic Regression</em> (2nd ed), p. 297)</p>
<p>Before we explain a “proportional odds model”, let’s just jump ahead and do it. Below we enter the data (since we don’t have the electronic source) and fit a proportional odds model using R:</p>
<pre class="r"><code># Table 8.6, Agresti 1996
party &lt;- factor(rep(c(&quot;Rep&quot;,&quot;Dem&quot;), c(407, 428)), 
                levels=c(&quot;Rep&quot;,&quot;Dem&quot;))  
rpi &lt;- c(30, 46, 148, 84, 99) # cell counts
dpi &lt;- c(80, 81, 171, 41, 55) # cell counts
ideology &lt;- c(&quot;Very Liberal&quot;,
              &quot;Slightly Liberal&quot;,
              &quot;Moderate&quot;,
              &quot;Slightly Conservative&quot;,
              &quot;Very Conservative&quot;)
pol.ideology &lt;- factor(c(rep(ideology, rpi), 
                         rep(ideology, dpi)), 
                       levels = ideology)
dat &lt;- data.frame(party, pol.ideology)

# fit proportional odds model
library(MASS)
pom &lt;- polr(pol.ideology ~ party, data=dat)</code></pre>
<p>Above we create a data frame with one row for each respondent. The first column we create is party, with 407 entries for Republican and 428 for Democratic. The next column we create is pol.ideology. We use the cell counts (stored as rpi and dpi, respectively) with the rep function to repeat each ideology a given number of times. For example, rep(ideology, rpi) repeats “Very Liberal” 30 times, “Slightly Liberal” 46 times, and so on. Finally we create a data frame called dat.</p>
<p>We fit the model using the <code>polr</code> function from the MASS package. “polr” stands for Proportional Odds Linear Regression. The MASS package comes with R. (Incidentally, MASS stands for <em>Modern Applied Statistics with S</em>, a book by W.N Venables and B.D. Ripley. R is an open-source implementation of S.)</p>
<p>Let’s take a look at the model summary:</p>
<pre class="r"><code>summary(pom)</code></pre>
<pre><code>## 
## Re-fitting to get Hessian</code></pre>
<pre><code>## Call:
## polr(formula = pol.ideology ~ party, data = dat)
## 
## Coefficients:
##            Value Std. Error t value
## partyDem -0.9745     0.1292  -7.545
## 
## Intercepts:
##                                         Value    Std. Error t value 
## Very Liberal|Slightly Liberal            -2.4690   0.1318   -18.7363
## Slightly Liberal|Moderate                -1.4745   0.1090   -13.5314
## Moderate|Slightly Conservative            0.2371   0.0942     2.5165
## Slightly Conservative|Very Conservative   1.0695   0.1039    10.2923
## 
## Residual Deviance: 2474.985 
## AIC: 2484.985</code></pre>
<p>We have one coefficient and four intercepts. If you’ve never done ordinal logistic regression before, this may seem baffling and backwards. We’ll explain in a moment. Let’s move ahead with using our model to make predictions. Below we use our model to generate probabilities for answering a particular ideology given party affiliation:</p>
<pre class="r"><code>predict(pom,newdata = data.frame(party=&quot;Dem&quot;),
        type=&quot;p&quot;)</code></pre>
<pre><code>##          Very Liberal      Slightly Liberal              Moderate 
##             0.1832505             0.1942837             0.3930552 
## Slightly Conservative     Very Conservative 
##             0.1147559             0.1146547</code></pre>
<pre class="r"><code>predict(pom,newdata = data.frame(party=&quot;Rep&quot;),
        type=&quot;p&quot;)</code></pre>
<pre><code>##          Very Liberal      Slightly Liberal              Moderate 
##            0.07806044            0.10819225            0.37275214 
## Slightly Conservative     Very Conservative 
##            0.18550357            0.25549160</code></pre>
<p>The <code>newdata</code> argument requires data be in a data frame, hence the <code>data.frame</code> function. The <code>type=“p”</code> argument says we want probabilities. The default is to return predicted class membership, which in this case would be “Moderate” since that’s the highest estimated probability for both parties.</p>
<p>As far as R code goes, this is pretty simple. We fit a proportional odds model and got our estimated probabilities. But why four intercepts? What does the partyDem coefficient mean? Is this even an appropriate model? And why is this called “proportional odds”?</p>
<p>To answer these questions we need to state the proportional odds model:</p>
<p><span class="math display">\[logit[P(Y \leq j)] = \alpha_j - \beta x, j = 1,...,J-1\]</span></p>
<p>On the right side of the equal sign we see a simple linear model with one slope, <span class="math inline">\(\beta\)</span>, and an intercept that changes depending on j, <span class="math inline">\(\alpha_j\)</span>. Here the j is the level of an ordered category with J levels. In our case, j = 1 would be “Very Liberal”. So we see we have a different intercept depending on the level of interest. Why does j only extend to J - 1? Because in this model we’re modeling the probability of being in one category (or lower) versus being in categories above it. In our example, <span class="math inline">\(P(Y \leq 2)\)</span> means the probability of being “Very Liberal” or “Slightly Liberal” versus being “Moderate” or above. Thus we’re using the levels as boundaries. In this model the highest level returns a probability of 1 (i.e., <span class="math inline">\(P(Y \leq J) = 1\)</span>), so we don’t model it.</p>
<p>Now what about the logit? That means log odds. It’s not the probability we model with a simple linear model, but rather the log odds of the probability. If probability is 0.75, the odds of success is 0.75/0.25 = 3. The log of 3 is about 1.09. So the logit of 0.75 is about 1.09.</p>
<p>The summary output of our model is stated in terms of this model. Since we have 5 levels, we get 5 - 1 = 4 intercepts. We have one predictor, so we have one slope coefficient. Plugging in values returns estimated log odds. Let’s try this. What’s the log odds a Democrat identifies as “Slightly Liberal” or lower? Plug in the appropriate values from the model output given above:</p>
<p><span class="math display">\[logit[P(Y \leq 2)] = -1.4745 - -0.9745(1) = -0.5\]</span></p>
<p>This isn’t terribly descriptive. Let’s convert to probability. The means taking the inverse logit. The formula for this is</p>
<p><span class="math display">\[P(Y \leq j) = \frac{exp(\alpha_j - \beta x)}{1 + exp(\alpha_j - \beta x)}\]</span></p>
<p>Applying to -0.5 we get</p>
<p><span class="math display">\[P(Y \leq 2) = exp(-0.5)/(1 + exp(-0.5)) = 0.378\]</span></p>
<p>This is cumulative probability. The probability of identifying as “Very Liberal” or “Slightly Liberal” when you’re a Democrat is about 0.378. This is why the labels for the intercepts in the summary output have a bar “|” between the category labels: they identify the boundaries.</p>
<p>So how did R calculate the probabilities for being in a particular category? In other words, how do we calculate <span class="math inline">\(P(Y = j)\)</span>? We do some subtraction:</p>
<p><span class="math display">\[P(Y = j) = P(Y \leq j) - P(Y \leq j - 1)\]</span></p>
<p>For example the probability of a Democrat identifying as “Slightly Liberal” is</p>
<p><span class="math display">\[P(Y = 2) = P(Y \leq 2) - P(Y \leq 1) = 0.378 - 0.183 = 0.195 \]</span></p>
<p>The baseline level in this model is Republican, so we set x = 0 when doing their calculations. The probability of a Republican identifying as “Slightly Liberal” or lower is simply</p>
<p><span class="math display">\[logit[P(Y \leq 2)] = -1.4745 - -0.9745(0) = -1.4745\]</span>
<span class="math display">\[P(Y \leq 2) = exp(-1.4745)/(1 + exp(-1.4745)) = 0.186\]</span></p>
<p>We can speed up these calculations by using elements of the <code>pom</code> object. The slope coefficient is stored in <code>pom$coefficient</code> and the intercepts are stored in <code>pom$zeta</code>. (The developers of the <code>polr</code> function like using zeta to represent the intercepts instead of alpha.) Here’s how to quickly calculate the cumulative ideology probabilities for both Democrats and Republicans:</p>
<pre class="r"><code># Democrat cumulative probabilities
exp(pom$zeta - pom$coefficients)/
  (1 + exp(pom$zeta - pom$coefficients))</code></pre>
<pre><code>##           Very Liberal|Slightly Liberal 
##                               0.1832505 
##               Slightly Liberal|Moderate 
##                               0.3775341 
##          Moderate|Slightly Conservative 
##                               0.7705894 
## Slightly Conservative|Very Conservative 
##                               0.8853453</code></pre>
<pre class="r"><code># Republican cumulative probabilities
exp(pom$zeta)/(1 + exp(pom$zeta))</code></pre>
<pre><code>##           Very Liberal|Slightly Liberal 
##                              0.07806044 
##               Slightly Liberal|Moderate 
##                              0.18625269 
##          Moderate|Slightly Conservative 
##                              0.55900483 
## Slightly Conservative|Very Conservative 
##                              0.74450840</code></pre>
<p>That hopefully explains the four intercepts and one slope coefficient. But why the name “proportional odds”? “Proportional” means that two ratios are equal. Recall that odds is the ratio of the probability of success to the probability of failure. In this case, “success” and “failure” correspond to <span class="math inline">\(P(Y \leq j)\)</span> and <span class="math inline">\(P(Y &gt; j)\)</span>, respectively. The ratio of those two probabilities gives us odds. We can quickly calculate the odds for all J-1 levels for both parties:</p>
<pre class="r"><code># Democrat cumulative probabilities
dcp &lt;- exp(pom$zeta - pom$coefficients)/
  (1 + exp(pom$zeta - pom$coefficients))
# Republican cumulative probabilities
rcp &lt;- exp(pom$zeta)/(1 + exp(pom$zeta))

# Democrat odds
(dcp/(1-dcp))</code></pre>
<pre><code>##           Very Liberal|Slightly Liberal 
##                               0.2243656 
##               Slightly Liberal|Moderate 
##                               0.6065138 
##          Moderate|Slightly Conservative 
##                               3.3589956 
## Slightly Conservative|Very Conservative 
##                               7.7218378</code></pre>
<pre class="r"><code># Republican odds 
(rcp/(1-rcp))</code></pre>
<pre><code>##           Very Liberal|Slightly Liberal 
##                               0.0846698 
##               Slightly Liberal|Moderate 
##                               0.2288827 
##          Moderate|Slightly Conservative 
##                               1.2675986 
## Slightly Conservative|Very Conservative 
##                               2.9140230</code></pre>
<p>Now let’s take the ratio of the Democratic ideology odds to the Republican ideology odds:</p>
<pre class="r"><code>(dcp/(1-dcp))/(rcp/(1-rcp))</code></pre>
<pre><code>##           Very Liberal|Slightly Liberal 
##                                2.649889 
##               Slightly Liberal|Moderate 
##                                2.649889 
##          Moderate|Slightly Conservative 
##                                2.649889 
## Slightly Conservative|Very Conservative 
##                                2.649889</code></pre>
<p>Look, they’re all the same. The odds ratios are equal, which means they’re proportional. And now we see why we call this a proportional odds model. For any level of ideology, the estimated odds that a Democrat’s response is in the liberal direction (to the left) rather than the conservative direction is about 2.6 times the odds for republicans. Or to put it more succinctly, Democrats have higher odds of being liberal. News flash! But seriously, that’s how you interpret odds ratios. Less than 1 means lower odds. More than 1 means higher odds. Since the baseline level of party is Republican, the odds ratio here refers to Democratic.</p>
<p>Let’s take the log of the odds ratios:</p>
<pre class="r"><code>log((dcp/(1-dcp))/(rcp/(1-rcp)))</code></pre>
<pre><code>##           Very Liberal|Slightly Liberal 
##                               0.9745178 
##               Slightly Liberal|Moderate 
##                               0.9745178 
##          Moderate|Slightly Conservative 
##                               0.9745178 
## Slightly Conservative|Very Conservative 
##                               0.9745178</code></pre>
<p>Does that number look familiar? It’s the slope coefficient in the model summary, without the minus sign. Some statistical programs, like R, tack on a minus sign so higher levels of predictors correspond to the response falling in the higher end of the ordinal scale. If we exponentiate the slope coefficient as estimated by R, we get exp(-0.9745) = 0.38. This means the estimated odds that a Democrat’s response in the conservative direction (to the right) is about 0.38 times the odds for Republicans. That is, they’re less likely to have an ideology at the conservative end of the scale. This isn’t exactly a ground-breaking political discovery, but we have somewhat quantified the relationship between political ideology and party affiliation (at least as it existed in 1991).</p>
<p>When fitting a proportional odds model, it’s a good idea to check the assumption of proportional odds. One way to do this is by comparing the proportional odds model with a multinomial logit model, also called an unconstrained baseline logit model. The multinomial logit model is typically used to model unordered responses and fits a slope to each level of the J - 1 responses. So whereas our proportional odds model has one slope coefficient and four intercepts, the multinomial model would have four intercepts and four slope coefficients. This suggests the proportional odds model is nested in the multinomial model, and that we could perform a likelihood ratio test to see if the models are statistically different. Here’s how we can do that in R:</p>
<pre class="r"><code>library(nnet)
mlm &lt;- multinom(pol.ideology ~ party, data=dat)</code></pre>
<pre><code>## # weights:  15 (8 variable)
## initial  value 1343.880657 
## iter  10 value 1239.866743
## final  value 1235.648615 
## converged</code></pre>
<pre class="r"><code>M1 &lt;- logLik(pom)
M2 &lt;- logLik(mlm)
(G &lt;- -2*(M1[1] - M2[1]))</code></pre>
<pre><code>## [1] 3.687678</code></pre>
<pre class="r"><code>pchisq(G,3,lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.2972241</code></pre>
<p>First we load the nnet package, which has the <code>multinom</code> function for fitting multinomial logistic models. (The nnet package comes with R.) Then we calculate -2 times the difference between log likelihoods to obtain a likelihood ratio test statistic and save as G. Finally we calculate a p-value using the <code>pchisq</code> function, which tells us the area under a chi-square distribution with 3 degrees of freedom beyond 3.68. The p-value is quite high which indicates the proportional odds model fits as well as the more complex multinomial logit model. Hosmer and Lemeshow tell us this test is not “completely statistically correct.” Nevertheless it does “provide some evidence of model adequacy.” (page 304)</p>
<div id="references" class="section level3">
<h3>References</h3>
<ul>
<li>Agresti, A. (1996). <em>An Introduction to Categorical Data Analysis</em>. Wiley.</li>
<li>Hosmer, D. and Lemeshow, S. (2000). <em>Applied Logistic Regression, 2 ed</em>. Wiley.</li>
</ul>
<p>For questions or clarifications regarding this article, contact the UVa Library StatLab: <a href="mailto:statlab@virginia.edu">statlab@virginia.edu</a></p>
<p><em>Clay Ford</em><br />
<em>Statistical Research Consultant</em><br />
<em>University of Virginia Library</em></p>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.6.0 (2019-04-26)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17134)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] nnet_7.3-12   MASS_7.3-51.4
## 
## loaded via a namespace (and not attached):
##  [1] compiler_3.6.0  magrittr_1.5    bookdown_0.9    tools_3.6.0    
##  [5] htmltools_0.3.6 yaml_2.2.0      Rcpp_1.0.1      stringi_1.4.3  
##  [9] rmarkdown_1.12  blogdown_0.11   knitr_1.22      stringr_1.4.0  
## [13] digest_0.6.18   xfun_0.6        evaluate_0.13</code></pre>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
		<p>&copy; 2020 by the Rector and Visitors of the <a href="http://www.virginia.edu">University of Virginia</a></p>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

